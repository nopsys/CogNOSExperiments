# Config file for ReBench
# Config format is YAML (see http://yaml.org/ for detailed spec)

# this run definition will be choosen if no parameters are given to rebench.py
default_experiment: all
default_data_file: 'cognos.data'

# settings and requirements for statistic evaluation
# Note, this is only used for explorative runs, for the final experiments, we
# rely soley on a fixed configuration of data points.
#statistics:
#    confidence_level: 0.95
 
# definition of benchmark suites
benchmark_suites:
    are-we-fast-st:
        gauge_adapter: RebenchLog
        command: " %(benchmark)s %(variable)s "
        variable_values:
              - 20
        max_invocation_time: 5500
        benchmarks: 
            - DeltaBlue:
                extra_args: 12000
            - Richards:
                extra_args: 100
            - Json:
                extra_args: 100
#            - CD:
#                extra_args: 100
            - Havlak:
                extra_args: 1500
            
            - Bounce:
                extra_args: 1500
            - List:
                extra_args: 1500
            - Mandelbrot:
                extra_args: 500
            - NBody:
                extra_args: 250000
            - Permute:
                extra_args: 1000
            - Queens:
                extra_args: 1000
            - Sieve:
                extra_args: 3000
            - Storage:
                extra_args: 1000
            - Towers:
                extra_args: 600    

    devices:
        gauge_adapter: RebenchLog
        command: " %(benchmark)s 40 "
        max_invocation_time: 5500
        benchmarks: 
            - FilesystemBench:
                extra_args: 1
        
# VMs have a name and are specified by a path and the binary to be executed
executors:
    Pharo-interpreter:
        path: 
        executable: ..
        args: 
    Pharo-JIT:
        path: ..
        executable: ..
    Pharo-interpreter-remote:
        path: 
        executable: &PHARO_REMOTE_COMMAND scripts/runExperimentsRemote.sh 
        args: "Ubuntu --interpreter ../../are-we-fast-yet/benchmarks/Smalltalk/run.st "
    Pharo-JIT-remote:
        executable: *PHARO_REMOTE_COMMAND
        args: "Ubuntu --jit ../../are-we-fast-yet/benchmarks/Smalltalk/run.st " 
    Pharo-interpreter-remote-fat32:
        executable: *PHARO_REMOTE_COMMAND
        args: "Ubuntu --interp ../../are-we-fast-yet/benchmarks/Smalltalk/run.st " 
    CogNOS-interpreter:
        path: 
        executable: &COGNOS_COMMAND scripts/runExperimentsInCogNOS.sh 
        args: "--interpreter"
    CogNOS-jit:
        path:
        executable: *COGNOS_COMMAND
        args: "--jit"
    CogNOS-jit-hd:
        path:
        executable: &COGNOS_COMMANDHD scripts/runExperimentsInCogNOSHD.sh 
        args: "--jit"
    CogNOS-interpreter-hd:
        path:
        executable: *COGNOS_COMMANDHD
        args: "--interpreter"
    CogNOS-interpreter-hd-ramdisk:
        path:
        executable: *COGNOS_COMMANDHD
        args: "--interp"


# define the benchmarks to be executed for a re-executable benchmark run
experiments:
    BasicPerformance:
        data_file: basicPerformance.data
        description: >
            dfdfds
        suites:
            - are-we-fast-st
        executions:
            - Pharo-interpreter-remote
            - Pharo-JIT-remote
            - CogNOS-interpreter
#            - CogNOS-jit
    
    DevicesPerformance:      
        data_file: devicesPerformance.data
        description: >
            dfdfds
        executions:
            - Pharo-interpreter-remote-fat32:
                suites:
                    - devices
            - Pharo-interpreter-remote:
                suites:
                    - devices
            - CogNOS-interpreter-hd:
                suites:
                    - devices
            - CogNOS-interpreter-hd-ramdisk:
                suites:
                    - devices
