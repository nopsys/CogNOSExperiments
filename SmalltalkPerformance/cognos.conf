# Config file for ReBench
# Config format is YAML (see http://yaml.org/ for detailed spec)

# this run definition will be choosen if no parameters are given to rebench.py
standard_experiment: all
standard_data_file: 'cognos.data'

runs:
    number_of_data_points: 5
    
are_we_fast_yet:
    ## this is ignored by rebench
    iteration_numbers:
        slow_vm_micro:      &SLOW_VM_MICRO      5

# settings and requirements for statistic evaluation
# Note, this is only used for explorative runs, for the final experiments, we
# rely soley on a fixed configuration of data points.
#statistics:
#    confidence_level: 0.95
 
# definition of benchmark suites
benchmark_suites:
    are-we-fast-st:
        gauge_adapter: RebenchLog
        location: ""
        command: " %(benchmark)s %(variable)s "
        variable_values: *SLOW_VM_MICRO ## the number iterations measured
        max_runtime: 6000
        benchmarks: 
            - DeltaBlue:
                extra_args: 12000
            - Richards:
                extra_args: 100
            - Json:
                extra_args: 100
#            - CD:
#                extra_args: 100
            - Havlak:
                extra_args: 1500
            
            - Bounce:
                extra_args: 1500
            - List:
                extra_args: 1500
            - Mandelbrot:
                extra_args: 500
            - NBody:
                extra_args: 250000
            - Permute:
                extra_args: 1000
            - Queens:
                extra_args: 1000
            - Sieve:
                extra_args: 3000
            - Storage:
                extra_args: 1000
           - Towers:
                extra_args: 600    

# VMs have a name and are specified by a path and the binary to be executed
virtual_machines:
    Pharo-interpreter:
        path: 
        binary: ..
        args: 
    Pharo-JIT:
        path: ..
        binary: 
    Pharo-interpreter-remote:
        path: 
        binary: &PHARO_REMOTE_COMMAND runExperimentsLocal.sh 
        args: "Ubuntu --interpreter ../../are-we-fast-yet/benchmarks/Smalltalk/run.st "
    Pharo-JIT-remote:
        binary: *PHARO_REMOTE_COMMAND
        args: "Ubuntu --jit ../../are-we-fast-yet/benchmarks/Smalltalk/run.st " 
    CogNOS-interpreter:
        path: 
        binary: runExperimentsInCogNOS.sh 
        args: "--interpreter"
    CogNOS-JIT:
        path: 
        binary: runExperimentsInCogNOS.sh 
        args: "--jit"
                
# define the benchmarks to be executed for a re-executable benchmark run
experiments:
    BasicPerformance:
        data_file: areWeFast.data
        description: >
            dfdfds
        benchmark:
            - are-we-fast-st
        executions:
          - Pharo-interpreter-remote
          - Pharo-JIT-remote
          - CogNOS-interpreter
#          - CogNOS-jit